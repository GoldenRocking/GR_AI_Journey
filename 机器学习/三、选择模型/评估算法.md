当不知道如何选择分离数据集的方法时，请选择K折交叉验证来分离数据集；

当不知道如何设定K值时，请将K值设为10。



**分离训练数据集和评估数据集：**

将原始数据集分为两部分，第一部分用来训练算法生成模型，第二部分通过模型来预测结果，并与已知的结果进行比较，来评估算法模型的准确度。

通常会将67%的数据作为训练集，将33%的数据作为评估数据集。



**K折交叉验证分离：**

K折交叉验证是将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，再用这K个模型最终的验证集的分类准确率的平均数，作为此K折交叉验证下分类器的性能指标。

K折交叉验证可以有效地避免过学习及欠学习状态的发生，最后得到的结果也比较具有说服力。

通常会取K为3、5、10来分离数据。



**弃一交叉验证分离：**

如果原始数据有N个样本，那么弃一交叉验证就是N-1个交叉验证，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以弃一交叉验证会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此次弃一交叉验证分类器的性能指标。

优点：

1. 每一回合中几乎所有的样本皆用于训练模型，因此最接近原始样本的分布，这样评估所得的结果比较可靠。

2. 实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的。



缺点：

1. 计算成本高，因为需要建立的模型数量与原始数据样本数量相同，当原始数据样本数量相当多时，弃一交叉验证在实际运行上便有困难



**重复随机分离评估数据集与训练数据集：**









